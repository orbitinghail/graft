#!/usr/bin/env bash
set -euo pipefail

GIT_ROOT="$(git rev-parse --show-toplevel)"

# set the PWD to the git root directory - sql tests expect this
cd "${GIT_ROOT}"

# invert diff colors so that expected lines are green
DIFF_PALETTE="ad=1;38;5;9:de=1;38;5;154"

# load the filter from the first argument
FILTER="${1:-}"

# build libgraft if it's not specified
LIBGRAFT="${LIBGRAFT:-}"
if [ -z "${LIBGRAFT}" ]; then
    cargo build --package graft-ext
    if [ $? -ne 0 ]; then
        echo "Cargo build failed"
        exit 1
    fi

    LIB_PATH="${GIT_ROOT}/target/debug"
    if [[ "$OSTYPE" == "msys" || "$OSTYPE" == "cygwin" ]]; then
        LIBGRAFT="${LIB_PATH}/graft_ext.dll"
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        LIBGRAFT="${LIB_PATH}/libgraft_ext.dylib"
    else
        LIBGRAFT="${LIB_PATH}/libgraft_ext.so"
    fi
fi

# test against our min supported sqlite version
export SQLITE_TEST=1

# run sqlite3.sh to ensure it's installed and print the version
just run sqlite bin --version

# select tests from *.sql files in GIT_ROOT, filtered by the first argument (substring)
declare TESTS=$(find "${GIT_ROOT}" -name "test_*.sql" | grep "${FILTER}")

if [ -z "${TESTS}" ]; then
    echo "No tests found using filter: ${FILTER}"
    echo "usage: $0 <filter>"
    echo "available tests:"
    find "${GIT_ROOT}" -name "test_*.sql"
    exit 1
fi

ANY_FAILED=0

SQLITE_ARGS=(
    -cmd ".log stderr"
    -cmd ".load '${LIBGRAFT}'"
    -header
    -table
    -echo
)

for TEST in ${TESTS}; do
    echo "Running test: ${TEST}"
    EXPECTED="${TEST}.expected"

    export GRAFT_DATA_DIR="$(mktemp -d)"
    export GRAFT_REMOTE__TYPE="memory"

    # We add the exit code to the output since SQLite returns the number of
    # errors encountered while executing, and some of the tests want to trigger
    # errors on purpose (thus we can't just fail on non-zero exit code).
    set +e
    OUTPUT=$(just run sqlite bin "${SQLITE_ARGS[@]}" 2>&1 <"${TEST}")
    EXIT_CODE=$?
    OUTPUT=$(printf "%s\n\n%s\n" "${OUTPUT}" "SQLite Exit Code = ${EXIT_CODE}")
    set -e

    if [ -n "${GRAFT_DATA_DIR}" ] && [ -z "${SKIP_CLEANUP:-}" ]; then
        rm -rf "${GRAFT_DATA_DIR}"
    fi

    # if UPDATE_EXPECTED is set in the env, then write out expected files
    if [ -n "${UPDATE_EXPECTED:-}" ]; then
        echo "Updating expected output for: ${TEST}"
        echo "${OUTPUT}" >"${EXPECTED}"
    elif [ -f "${EXPECTED}" ]; then
        set +e
        DIFF=$(echo "${OUTPUT}" | diff --color=always --palette="${DIFF_PALETTE}" -u --label "Expected Output" "${EXPECTED}" --label "Actual output" -)
        set -e
        if [ -n "${DIFF}" ]; then
            echo "TEST FAILURE: Diff between actual and expected output for: ${TEST}"
            echo "${DIFF}"
            echo "Test failed: ${TEST}"
            echo "Expected file: ${EXPECTED}"
            echo "You can update the expected file by running:"
            echo "UPDATE_EXPECTED=1 $0 ${FILTER}"
            ANY_FAILED=1
        fi
    else
        echo "${OUTPUT}"

        # no expected file, fail
        echo "No expected output found for: ${TEST}"
        echo "You can create one by setting the UPDATE_EXPECTED environment variable and re-running the tests"
        exit 1
    fi
done

exit $ANY_FAILED
